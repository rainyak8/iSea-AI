# iSea-AI
基于 twelvet-fast 脚手架实现的单体服务。
## 🌈 项目背景

---
随着人工智能技术的快速发展，大语言模型（LLM）在各个领域的应用日益广泛。作为一款性能卓越的语言模型，**DeepSeek** 凭借其强大的语言理解能力、生成能力和多场景适应性，成为众多企业和个人用户的首选工具。与此同时，**Dify** 以其先进的编排能力、知识库管理和灵活的 API 接入方式，为构建智能化对话平台提供了强有力的支持。为了满足终端用户对高性能对话服务的需求，同时保障数据隐私和系统可控性，我们决定打造一个基于自部署 **DeepSeek** 模型并接入 **Dify** 的对话平台，面向 **ToC 用户** 提供安全、高效且智能化的服务。

## 🎯 项目目标

---
本项目旨在构建一个自部署的 **DeepSeek** 对话平台，并通过接入 **Dify** 实现其先进的编排与知识库能力，为用户提供流畅、智能且高度定制化的对话体验。具体目标包括：

1. **自部署 DeepSeek 模型**：

    - 将 **DeepSeek** 模型部署在本地服务器或私有云环境中，确保用户数据完全掌控在自己手中，避免敏感信息泄露的风险。

   - 利用容器化技术（如 Docker）实现统一的环境管理，确保模型部署的高效性和可维护性。

2. **接入 Dify 平台**：

    - 借助 **Dify** 的编排能力，优化对话流程，提升用户体验。

   - 利用 **Dify** 的知识库功能，支持动态知识更新和扩展，为用户提供更精准的回答和服务。

   - 通过 **Dify2OpenAI** 等工具解决接口兼容性问题，确保 **DeepSeek** 模型与 **Dify** 平台无缝对接。

3. **构建用户友好的对话平台**：

    - 开发直观易用的前端界面，支持多设备访问，降低用户学习成本。

   - 提供流式对话能力，确保实时性和互动性，提升用户体验。

4. **多用户支持与隔离**：

    - 设计完善的用户管理系统，实现多用户隔离和权限控制，确保每位用户的数据独立性和安全性。

   - 支持用户自定义上下文长度和会话管理，满足个性化需求。

5. **可扩展性与灵活性**：

    - 通过模块化设计，支持未来功能扩展（如工具集成、API 扩展等），满足不同场景下的用户需求。

   - 引入云端存储服务，实现聊天记录扩展，保证用户体验。

## 🧾 项目概述

---
为了实现上述目标，我们将采用一系列先进的技术和工具，确保项目的高效开发与稳定运行：

1. **模型部署**：

   - 使用 **Ollama** 或其他开源框架统一接入 **DeepSeek** 模型，简化自部署流程。

   - 通过 **Docker** 容器化管理，确保模型运行环境的一致性和可移植性。

2. **后端架构**：

    - 采用 **Java + Spring Boot + Spring AI Alibaba** 构建后端服务，提供 RESTful API 和 WebSocket 接口，支持流式对话和上下文管理。

   - 使用 **MySQL** 存储用户数据、会话记录和日志信息；引入 **Redis** 作为缓存层，用于上下文管理、会话锁以及高频数据的快速访问。

3. **Dify 集成**：

    - 借助 **Dify** 的编排能力，优化对话逻辑，提升系统的智能化水平。

   - 利用 **Dify** 的知识库功能，支持用户上传和管理知识库内容，并通过向量化处理实现高效检索。

   - 解决 **Dify** 与 **DeepSeek** 的接口兼容性问题，使用 **Dify2OpenAI** 工具实现 OpenAPI 规范的统一接入。

4. **前端界面**：

    - 开发直观易用的用户界面，支持多设备访问，降低用户学习成本。

   - 提供实时对话反馈和上下文提示，增强用户体验。

5. **安全性保障**：

    - 实现基于 Token 的鉴权机制，确保 API 请求的安全性。

   - 通过加密存储和传输保护用户隐私，满足数据安全合规要求。

6. **云端扩展**：

    - 未来计划接入云端存储服务（如 AWS S3 或阿里云 OSS），进一步优化消息记录存储和检索效率。

   - 引入分布式缓存（如 Redis Cluster）和消息队列（如 Kafka 或 RabbitMQ），提升系统的并发处理能力。
:::

## 🗓️ 项目进展

---
[请至钉钉文档查看「多维表」](https://docs.dingtalk.com/i/nodes/1OQX0akWmx7vjekXFkglL1YR8GlDd3mE?iframeQuery=anchorId%3DX0278ae71d1-8881-4e06-a4dc-2ab309e2b0dc-m7e5pcjrevjlvi8pjia)

## 🧑‍💻 团队成员

---

| 岗位     | 负责人                | 职责              | 联系方式 |
| -------- | --------------------- | ----------------- | -------- |
| 后端开发 | 刘志坚 | 基架+AI对话领域 | rainyak  |
| 后端开发 | 杨宇豪 | \-                |          |
| 后端开发 | 李安琦 | \-                |          |

## ⌛ 项目进度

---

开发请新拉分支，自测通过后再合并master！！！
### 要求
- jdk >= 17
- maven >= 3.8
- Spring Boot >= 3.x
- 脚手架前端源码：https://github.com/twelvet-s/twelvet-ui

## 脚手架在线体验

---

- admin/123456

演示地址：[https://cloud.twelvet.cn](https://cloud.twelvet.cn)

## 支持Linux一件Docker启动

---
内存 > 16
需要自行安装maven、docker、docker-compose、node、yarn
```shell
# mvn
mvn clean && mvn install
# 进入脚本目录
cd ./docker
# 可执行权限
chmod 751 deploy.sh
# 执行启动（按需执行参数，[init|port|base|server|stop|rm]）
# 初始化
./deploy.sh init
# 基础服务
./deploy.sh base
# 启动twelvet
./deploy.sh server
# 启动UI
./deploy.sh nginx
```